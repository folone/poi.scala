name: Benchmark Comment

on:
  workflow_run:
    workflows: ["CI Pipeline"]
    types:
      - completed

jobs:
  benchmark-comment:
    runs-on: ubuntu-latest
    if: github.event.workflow_run.conclusion == 'success'
    steps:
      - name: Debug workflow info
        run: |
          echo "Triggering workflow: ${{ github.event.workflow_run.name }}"
          echo "Run ID: ${{ github.event.workflow_run.id }}"
          echo "Conclusion: ${{ github.event.workflow_run.conclusion }}"
          echo "Event: ${{ github.event.workflow_run.event }}"
          echo "Pull requests: ${{ toJson(github.event.workflow_run.pull_requests) }}"
      - name: Checkout repository
        uses: actions/checkout@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0 # Fetch all history for all branches
      - name: Get PR number
        id: get-pr
        if: github.event.workflow_run.event == 'pull_request'
        run: |
          # Try to get PR number from workflow_run data using jq to safely parse
          PR_DATA='${{ toJson(github.event.workflow_run.pull_requests) }}'
          PR_NUM=$(echo "$PR_DATA" | jq -r '.[0].number // empty' 2>/dev/null || echo "")

          # If that's empty, try to find it from the head commit
          if [ -z "$PR_NUM" ] || [ "$PR_NUM" = "null" ]; then
            echo "PR number not found in workflow_run data, searching by commit..."
            # Get the head SHA from the workflow run
            HEAD_SHA="${{ github.event.workflow_run.head_sha }}"

            # Search for PRs with this commit
            PR_NUM=$(gh pr list --state all --search "$HEAD_SHA" --json number --jq '.[0].number // empty')
          fi

          if [ -n "$PR_NUM" ] && [ "$PR_NUM" != "null" ]; then
            echo "Found PR number: $PR_NUM"
            echo "pr-number=$PR_NUM" >> $GITHUB_OUTPUT
          else
            echo "Could not determine PR number"
            echo "pr-number=" >> $GITHUB_OUTPUT
          fi
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      - name: Download all benchmark results
        id: download-benchmarks
        uses: actions/download-artifact@v5
        with:
          pattern: "benchmark-results-*" # Download all benchmark result artifacts
          run-id: ${{ github.event.workflow_run.id }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          merge-multiple: true # Merge all artifacts into a single directory
        continue-on-error: true # Don't fail if no benchmark artifacts exist

      - name: Check if benchmarks were downloaded
        id: check-benchmarks
        run: |
          if ls benchmark-results-*.json 1> /dev/null 2>&1; then
            echo "found=true" >> $GITHUB_OUTPUT
            echo "Found benchmark result files:"
            ls -la benchmark-results-*.json
          else
            echo "found=false" >> $GITHUB_OUTPUT
            echo "No benchmark result files found - benchmarks may have been skipped"
          fi

      - name: Combine benchmark results
        id: combine-results
        if: steps.check-benchmarks.outputs.found == 'true'
        run: |
          # Combine all benchmark JSON files into a single file for processing
          echo "Combining benchmark results..."
          if ls benchmark-results-*.json 1> /dev/null 2>&1; then
            # Each file contains a JMH results array, so we need to merge the arrays
            echo "Processing individual benchmark files:"
            ls -la benchmark-results-*.json
            
            # Use jq to properly merge all JSON arrays into one
            jq -s 'map(.[]) | flatten' benchmark-results-*.json > benchmark-results.json
            
            RESULT_COUNT=$(jq length benchmark-results.json 2>/dev/null || echo "0")
            echo "Combined $RESULT_COUNT benchmark results"
            ls -la benchmark-results.json
            
            # Check if we have actual benchmark data (not just empty arrays)
            if [ "$RESULT_COUNT" -gt 0 ]; then
              echo "has-results=true" >> $GITHUB_OUTPUT
              echo "‚úÖ Found valid benchmark results"
              # Debug: show first few lines of the combined file
              echo "Sample of combined results:"
              head -20 benchmark-results.json
            else
              echo "has-results=false" >> $GITHUB_OUTPUT
              echo "‚ö†Ô∏è No actual benchmark results found (only empty arrays)"
            fi
          else
            echo "No benchmark result files found"
            echo "[]" > benchmark-results.json
            echo "has-results=false" >> $GITHUB_OUTPUT
          fi

      - name: Compare benchmark results
        if: steps.check-benchmarks.outputs.found == 'true' && steps.combine-results.outputs.has-results == 'true'
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: JMH Benchmarks
          tool: "jmh"
          output-file-path: benchmark-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          # Do not fail the build, just comment on the PR.
          fail-on-alert: false

      - name: Post benchmark page link
        if: |
          github.event.workflow_run.event == 'pull_request' && 
          steps.get-pr.outputs.pr-number != '' && 
          steps.check-benchmarks.outputs.found == 'true' &&
          steps.combine-results.outputs.has-results == 'true'
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ steps.get-pr.outputs.pr-number }}
          body: |
            üìä **Benchmark Results**

            Performance benchmarks have completed successfully! The detailed results are available for review:

            [View Benchmark Report](https://folone.github.io/poi.scala/dev/bench/)

            **Benchmark Coverage:**
            - ‚úÖ Core POI operations (dataSize=1000)
            - ‚úÖ Async operations (dataSize=100) 
            - ‚úÖ Memory efficiency (dataSize=5000)

            > üí° **Note**: This is an optimized benchmark suite for faster PR feedback. 
            > Comprehensive benchmarks with full parameter matrix run automatically on master branch.

      - name: Post no benchmarks comment
        if: |
          github.event.workflow_run.event == 'pull_request' && 
          steps.get-pr.outputs.pr-number != '' && 
          (steps.check-benchmarks.outputs.found == 'false' || steps.combine-results.outputs.has-results == 'false')
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ steps.get-pr.outputs.pr-number }}
          body: |
            üìä **Benchmark Results**

            No benchmark results were generated for this PR. This can happen when:
            - Benchmarks were skipped due to compilation issues
            - JMH failed to create output files (directory issues)
            - The workflow was triggered from a schedule event
            - Benchmark jobs were filtered out due to conditions

            If you expected benchmarks to run, please check the [workflow logs](${{ github.event.workflow_run.html_url }}) for details.

      - name: Log when PR number not found
        if: github.event.workflow_run.event == 'pull_request' && steps.get-pr.outputs.pr-number == ''
        run: |
          echo "‚ö†Ô∏è Could not determine PR number for commenting"
          echo "This might happen with external PRs or due to GitHub API limitations"
