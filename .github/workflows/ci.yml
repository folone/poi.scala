name: CI Pipeline
on:
  pull_request:
  push:
    branches: [master]
  schedule:
    - cron: "0 0 * * 0"

jobs:
  # REQUIRED JOBS - These must pass for PR to be merged
  code-quality:
    name: Code Quality & Formatting
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v5
      - uses: actions/setup-java@v5
        with:
          java-version: 11
          distribution: temurin
      - uses: coursier/cache-action@v6
      - uses: sbt/setup-sbt@v1
      - name: Check code formatting
        run: sbt scalafmtSbtCheck "+scalafmtCheckAll"
      - name: Compile and check for warnings
        run: |
          if sbt "+compile"; then
            echo "‚úÖ Compilation successful"
          else
            echo "‚ùå Compilation failed - please check source code"
            exit 1
          fi
      - name: Run scalastyle
        run: sbt scalastyle

  test:
    name: Test Suite (${{ matrix.java }}, ${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        include:
          - java: 8
            os: windows-latest
          - java: 8
            os: ubuntu-latest
          - java: 11
            os: ubuntu-latest
          - java: 17
            os: ubuntu-latest
    steps:
      - run: "git config --global core.autocrlf false"
        shell: bash
      - uses: actions/checkout@v5
      - uses: actions/setup-java@v5
        with:
          java-version: "${{ matrix.java }}"
          distribution: temurin
      - uses: coursier/cache-action@v6
      - uses: sbt/setup-sbt@v1
      - name: Run comprehensive test suite
        shell: bash
        run: |
          # First check if compilation works
          if ! sbt "Test/compile"; then
            echo "‚ùå Test compilation failed"
            exit 1
          fi

          # Then run tests
          sbt -v \
            "+compile" \
            "+test"

  property-based-testing:
    name: Extended Property-Based Testing
    runs-on: ubuntu-latest
    strategy:
      matrix:
        scala-version: ["2.12.20", "2.13.17", "3.3.7"]
    steps:
      - uses: actions/checkout@v5
      - uses: actions/setup-java@v5
        with:
          java-version: 11
          distribution: temurin
      - uses: coursier/cache-action@v6
      - uses: sbt/setup-sbt@v1
      - name: Run extended property-based tests
        run: |
          sbt "++${{ matrix.scala-version }}" \
            "testOnly *PropertyBasedTestingSpec" \
            "testOnly *TypeclassLawsSpec"

  integration-testing:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [test]
    steps:
      - uses: actions/checkout@v5
      - uses: actions/setup-java@v5
        with:
          java-version: 11
          distribution: temurin
      - uses: coursier/cache-action@v6
      - uses: sbt/setup-sbt@v1
      - name: Run integration tests
        run: |
          sbt "testOnly *IntegrationSpec"
      - name: Validate generated files
        run: |
          find . -name "*.xlsx" -type f | head -5
          echo "‚úÖ Excel files generated successfully"

  # OPTIONAL JOBS - These can fail without blocking PR merge
  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    if: github.event_name != 'schedule'
    needs: [test]
    continue-on-error: true # Don't fail the entire workflow if benchmarks fail
    strategy:
      matrix:
        benchmark-type: ["core", "async", "memory"]
      fail-fast: false
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0 # Need full history for performance comparison
      - uses: actions/setup-java@v5
        with:
          java-version: 11
          distribution: temurin
      - uses: coursier/cache-action@v6
      - uses: sbt/setup-sbt@v1
      - name: Check if JMH compiles
        run: |
          if sbt "benchmarks/Jmh/compile"; then
            echo "‚úÖ JMH compilation successful"
          else
            echo "‚ùå JMH compilation failed, skipping benchmarks"
            exit 0
          fi
      - name: Run optimized JMH benchmarks
        run: |
          case "${{ matrix.benchmark-type }}" in
            "core")
              # Run core benchmarks with reduced parameters for faster execution
              if sbt 'benchmarks/Jmh/run -p dataSize=1000 -rf json -rff benchmark-results-core.json .*PoiBenchmarks.*'; then
                echo "‚úÖ Core benchmarks completed successfully"
              else
                echo "‚ùå Core benchmarks failed, creating empty results file"
                echo "[]" > benchmark-results-core.json
              fi
              ;;
            "async")
              # Run async benchmarks with smaller dataset
              if sbt 'benchmarks/Jmh/run -p dataSize=100 -rf json -rff benchmark-results-async.json .*AsyncPoiBenchmarks.*'; then
                echo "‚úÖ Async benchmarks completed successfully"
              else
                echo "‚ùå Async benchmarks failed, creating empty results file"
                echo "[]" > benchmark-results-async.json
              fi
              ;;
            "memory")
              # Run memory benchmarks with single data size for efficiency
              export SBT_OPTS="-Xmx2g -XX:+UseG1GC"
              if sbt 'benchmarks/Jmh/run -p dataSize=5000 -rf json -rff benchmark-results-memory.json .*MemoryBenchmarks.*'; then
                echo "‚úÖ Memory benchmarks completed successfully"
              else
                echo "‚ùå Memory benchmarks failed, creating empty results file"
                echo "[]" > benchmark-results-memory.json
              fi
              ;;
          esac

          # Verify the results file exists and has content
          result_file="benchmark-results-${{ matrix.benchmark-type }}.json"

          # Check both project root and benchmarks directory
          if [ -f "$result_file" ] && [ -s "$result_file" ]; then
            echo "‚úÖ Results file found in project root: $result_file"
            ls -la "$result_file"
          elif [ -f "benchmarks/$result_file" ] && [ -s "benchmarks/$result_file" ]; then
            echo "‚úÖ Results file found in benchmarks directory, moving to root"
            mv "benchmarks/$result_file" "$result_file"
            ls -la "$result_file"
          else
            echo "‚ö†Ô∏è Results file missing or empty in both locations, creating fallback"
            echo "üîç Debugging: Let's find where JMH actually wrote files..."
            echo "Current working directory: $(pwd)"
            echo "Files in project root:"
            ls -la *.json 2>/dev/null || echo "No JSON files in root"
            echo "Files in benchmarks directory:"
            ls -la benchmarks/*.json 2>/dev/null || echo "No JSON files in benchmarks/"
            echo "Searching for any JSON files containing 'benchmark':"
            find . -name "*benchmark*.json" -type f 2>/dev/null | head -10
            echo "Creating fallback file..."
            echo "[]" > "$result_file"
          fi
      - name: Store benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ matrix.benchmark-type }}
          path: benchmark-results-*.json

  # Full comprehensive benchmarks - only run on master branch push
  comprehensive-benchmarks:
    name: Comprehensive Performance Suite
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/master'
    needs: [test]
    continue-on-error: true
    steps:
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0
      - uses: actions/setup-java@v5
        with:
          java-version: 11
          distribution: temurin
      - uses: coursier/cache-action@v6
      - uses: sbt/setup-sbt@v1
      - name: Run full benchmark suite
        run: |
          # Run all benchmarks with all parameter combinations (comprehensive)
          export SBT_OPTS="-Xmx4g -XX:+UseG1GC"
          echo "üîç Starting comprehensive benchmarks from directory: $(pwd)"
          if sbt 'benchmarks/Jmh/run -rf json -rff comprehensive-results.json'; then
            echo "‚úÖ Comprehensive benchmarks completed successfully"
            if [ -f "comprehensive-results.json" ]; then
              echo "‚úÖ Found comprehensive-results.json in project root"
              ls -la comprehensive-results.json
            elif [ -f "benchmarks/comprehensive-results.json" ]; then
              echo "‚úÖ Found comprehensive-results.json in benchmarks directory, moving to root"
              mv "benchmarks/comprehensive-results.json" "comprehensive-results.json"
              ls -la comprehensive-results.json
            else
              echo "‚ö†Ô∏è comprehensive-results.json not found in either location"
              echo "üîç Searching for comprehensive results files..."
              echo "Files in project root:"
              ls -la *.json 2>/dev/null || echo "No JSON files in root"
              echo "Files in benchmarks directory:"
              ls -la benchmarks/*.json 2>/dev/null || echo "No JSON files in benchmarks/"
              find . -name "*comprehensive*.json" -o -name "*results*.json" 2>/dev/null | head -10
            fi
          else
            echo "‚ùå Comprehensive benchmarks failed, creating empty results file"
            echo "[]" > comprehensive-results.json
          fi
      - name: Validate comprehensive benchmark results
        id: validate-results
        if: always() # Run even if benchmarks failed
        run: |
          if [ -f "comprehensive-results.json" ] && [ -s "comprehensive-results.json" ]; then
            RESULT_COUNT=$(jq length comprehensive-results.json 2>/dev/null || echo "0")
            if [ "$RESULT_COUNT" -gt 0 ]; then
              echo "‚úÖ Found $RESULT_COUNT comprehensive benchmark results"
              echo "has-results=true" >> $GITHUB_OUTPUT
            else
              echo "‚ö†Ô∏è No actual benchmark results found (empty or invalid JSON)"
              echo "has-results=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ö†Ô∏è Comprehensive results file missing or empty"
            echo "has-results=false" >> $GITHUB_OUTPUT
          fi
      - name: Compare comprehensive benchmark results
        if: steps.validate-results.outputs.has-results == 'true'
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: JMH Comprehensive Benchmarks
          tool: "jmh"
          output-file-path: comprehensive-results.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          fail-on-alert: false
      - name: Log comprehensive benchmark completion
        if: always()
        run: |
          if [ -f "comprehensive-results.json" ] && [ -s "comprehensive-results.json" ]; then
            BENCHMARK_COUNT=$(jq length comprehensive-results.json 2>/dev/null || echo "0")
            echo "üéØ Comprehensive benchmarks completed with $BENCHMARK_COUNT results"
            echo "üìä Performance data has been published to: https://folone.github.io/poi.scala/dev/bench/"
          else
            echo "‚ö†Ô∏è Comprehensive benchmarks completed but no valid results generated"
          fi

  # REQUIRED STATUS CHECK - All critical jobs must pass
  required-checks:
    name: Required Checks Summary
    runs-on: ubuntu-latest
    needs: [code-quality, test, property-based-testing, integration-testing]
    if: always()
    steps:
      - name: Check build status
        run: |
          echo "üîç Required Check Results:"
          echo "Code Quality: ${{ needs.code-quality.result }}"
          echo "Test Suite: ${{ needs.test.result }}"
          echo "Property-Based Testing: ${{ needs.property-based-testing.result }}"
          echo "Integration Testing: ${{ needs.integration-testing.result }}"

          # All required jobs must succeed
          if [[ "${{ needs.code-quality.result }}" == "success" && 
                "${{ needs.test.result }}" == "success" && 
                "${{ needs.property-based-testing.result }}" == "success" && 
                "${{ needs.integration-testing.result }}" == "success" ]]; then
            echo "‚úÖ All required checks passed!"
            echo "Note: Performance benchmarks and memory tests are optional"
          else
            echo "‚ùå Some required checks failed"
            exit 1
          fi
